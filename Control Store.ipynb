{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755e2423-4109-42e8-a572-bee0febd705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f3d75b9-81e1-4f9f-8652-164ea046412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/user/Desktop/Data Science or Data Analytics/Github/Data-Analytics-on-Chips-Category/cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9745e77-9be2-463c-af80-6e90e08a2eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>STORE_NBR</th>\n",
       "      <th>LYLTY_CARD_NBR</th>\n",
       "      <th>TXN_ID</th>\n",
       "      <th>PROD_NBR</th>\n",
       "      <th>PROD_NAME</th>\n",
       "      <th>PROD_QTY</th>\n",
       "      <th>TOT_SALES</th>\n",
       "      <th>PACK_SIZE(g)</th>\n",
       "      <th>BRAND_NAME</th>\n",
       "      <th>LIFESTAGE</th>\n",
       "      <th>PREMIUM_CUSTOMER</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>19</td>\n",
       "      <td>19205</td>\n",
       "      <td>16466</td>\n",
       "      <td>26</td>\n",
       "      <td>Pringles Sweet&amp;Spcy BBQ 134g</td>\n",
       "      <td>1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>134</td>\n",
       "      <td>Pringles</td>\n",
       "      <td>OLDER SINGLES/COUPLES</td>\n",
       "      <td>Mainstream</td>\n",
       "      <td>2018-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>189</td>\n",
       "      <td>189381</td>\n",
       "      <td>190189</td>\n",
       "      <td>84</td>\n",
       "      <td>GrnWves Plus Btroot &amp; Chilli Jam 180g</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>180</td>\n",
       "      <td>Grain</td>\n",
       "      <td>OLDER FAMILIES</td>\n",
       "      <td>Mainstream</td>\n",
       "      <td>2018-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>124</td>\n",
       "      <td>124236</td>\n",
       "      <td>127984</td>\n",
       "      <td>104</td>\n",
       "      <td>Infuzions Thai SweetChili PotatoMix 110g</td>\n",
       "      <td>1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>110</td>\n",
       "      <td>Infuzions</td>\n",
       "      <td>OLDER FAMILIES</td>\n",
       "      <td>Budget</td>\n",
       "      <td>2018-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>70</td>\n",
       "      <td>70131</td>\n",
       "      <td>68241</td>\n",
       "      <td>60</td>\n",
       "      <td>Kettle Tortilla ChpsFeta&amp;Garlic 150g</td>\n",
       "      <td>2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>150</td>\n",
       "      <td>Kettle</td>\n",
       "      <td>RETIREES</td>\n",
       "      <td>Premium</td>\n",
       "      <td>2018-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>33</td>\n",
       "      <td>33140</td>\n",
       "      <td>30342</td>\n",
       "      <td>10</td>\n",
       "      <td>RRD SR Slow Rst     Pork Belly 150g</td>\n",
       "      <td>2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>150</td>\n",
       "      <td>RRD</td>\n",
       "      <td>YOUNG FAMILIES</td>\n",
       "      <td>Mainstream</td>\n",
       "      <td>2018-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE  STORE_NBR  LYLTY_CARD_NBR  TXN_ID  PROD_NBR  \\\n",
       "0  2018-07-03         19           19205   16466        26   \n",
       "1  2018-07-03        189          189381  190189        84   \n",
       "2  2018-07-03        124          124236  127984       104   \n",
       "3  2018-07-03         70           70131   68241        60   \n",
       "4  2018-07-03         33           33140   30342        10   \n",
       "\n",
       "                                  PROD_NAME  PROD_QTY  TOT_SALES  \\\n",
       "0              Pringles Sweet&Spcy BBQ 134g         1        3.7   \n",
       "1     GrnWves Plus Btroot & Chilli Jam 180g         1        3.1   \n",
       "2  Infuzions Thai SweetChili PotatoMix 110g         1        3.8   \n",
       "3      Kettle Tortilla ChpsFeta&Garlic 150g         2        9.2   \n",
       "4       RRD SR Slow Rst     Pork Belly 150g         2        5.4   \n",
       "\n",
       "   PACK_SIZE(g) BRAND_NAME              LIFESTAGE PREMIUM_CUSTOMER    Month  \n",
       "0           134   Pringles  OLDER SINGLES/COUPLES       Mainstream  2018-07  \n",
       "1           180      Grain         OLDER FAMILIES       Mainstream  2018-07  \n",
       "2           110  Infuzions         OLDER FAMILIES           Budget  2018-07  \n",
       "3           150     Kettle               RETIREES          Premium  2018-07  \n",
       "4           150        RRD         YOUNG FAMILIES       Mainstream  2018-07  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "262147a4-809d-4ef7-a6f8-05660f4feffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dtype for date to datetime format\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4a32766-32b6-4ec8-84b1-14be10831ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 264836 entries, 0 to 264835\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   DATE              264836 non-null  datetime64[ns]\n",
      " 1   STORE_NBR         264836 non-null  int64         \n",
      " 2   LYLTY_CARD_NBR    264836 non-null  int64         \n",
      " 3   TXN_ID            264836 non-null  int64         \n",
      " 4   PROD_NBR          264836 non-null  int64         \n",
      " 5   PROD_NAME         264836 non-null  object        \n",
      " 6   PROD_QTY          264836 non-null  int64         \n",
      " 7   TOT_SALES         264836 non-null  float64       \n",
      " 8   PACK_SIZE(g)      264836 non-null  int64         \n",
      " 9   BRAND_NAME        264836 non-null  object        \n",
      " 10  LIFESTAGE         264836 non-null  object        \n",
      " 11  PREMIUM_CUSTOMER  264836 non-null  object        \n",
      " 12  Month             264836 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(6), object(5)\n",
      "memory usage: 26.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eb6aca-3b9d-4055-8b41-967541da6d41",
   "metadata": {},
   "source": [
    "# GETTING THE METRICS THAT'LL BE USED TO FIND THE CONTROL STORES\n",
    "\n",
    "METRICS TO FIND:\n",
    "* total sales revenue\r",
    "* total number of customers\n",
    "* Average number of transactions per customer\n",
    "\r\n",
    "Consider the monthly sales experience of eachcustomer\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e21d8862-f1f4-46b1-b840-7f1ac3dbc8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>STORE_NBR</th>\n",
       "      <th>M_SalesRevenue</th>\n",
       "      <th>M_NumberOfCustomers</th>\n",
       "      <th>M_AvgTranscPerCustomers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07</td>\n",
       "      <td>1</td>\n",
       "      <td>183.4</td>\n",
       "      <td>46</td>\n",
       "      <td>1.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07</td>\n",
       "      <td>2</td>\n",
       "      <td>141.2</td>\n",
       "      <td>36</td>\n",
       "      <td>1.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07</td>\n",
       "      <td>3</td>\n",
       "      <td>1140.1</td>\n",
       "      <td>106</td>\n",
       "      <td>1.235849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07</td>\n",
       "      <td>4</td>\n",
       "      <td>1326.5</td>\n",
       "      <td>122</td>\n",
       "      <td>1.245902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07</td>\n",
       "      <td>5</td>\n",
       "      <td>776.2</td>\n",
       "      <td>90</td>\n",
       "      <td>1.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3411</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>268</td>\n",
       "      <td>10.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3412</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>269</td>\n",
       "      <td>65.2</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3413</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>270</td>\n",
       "      <td>32.2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3414</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>271</td>\n",
       "      <td>76.4</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>272</td>\n",
       "      <td>16.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3416 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Month  STORE_NBR  M_SalesRevenue  M_NumberOfCustomers  \\\n",
       "0     2018-07          1           183.4                   46   \n",
       "1     2018-07          2           141.2                   36   \n",
       "2     2018-07          3          1140.1                  106   \n",
       "3     2018-07          4          1326.5                  122   \n",
       "4     2018-07          5           776.2                   90   \n",
       "...       ...        ...             ...                  ...   \n",
       "3411  2019-07        268            10.4                    2   \n",
       "3412  2019-07        269            65.2                    8   \n",
       "3413  2019-07        270            32.2                    4   \n",
       "3414  2019-07        271            76.4                   11   \n",
       "3415  2019-07        272            16.8                    2   \n",
       "\n",
       "      M_AvgTranscPerCustomers  \n",
       "0                    1.043478  \n",
       "1                    1.055556  \n",
       "2                    1.235849  \n",
       "3                    1.245902  \n",
       "4                    1.277778  \n",
       "...                       ...  \n",
       "3411                 1.000000  \n",
       "3412                 1.000000  \n",
       "3413                 1.000000  \n",
       "3414                 1.000000  \n",
       "3415                 1.000000  \n",
       "\n",
       "[3416 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_metrics(df):\n",
    "\n",
    "    # Grouping by STORE_NBR and month (M) from the DATE column\n",
    "    df['Month'] = df['DATE'].dt.to_period('M')\n",
    "    \n",
    "    # Total sales revenue\n",
    "    T_sales = df.groupby([ 'Month','STORE_NBR'])['TOT_SALES'].sum().reset_index()\n",
    "\n",
    "    # Total number of customers\n",
    "    T_Cust = df.groupby(['Month', 'STORE_NBR'])['LYLTY_CARD_NBR'].nunique().reset_index()\n",
    "\n",
    "    # Average number of transactions per customer\n",
    "    Avg_Tcust =  df.groupby(['Month', 'STORE_NBR'])['LYLTY_CARD_NBR'].count() / \\\n",
    "                df.groupby(['Month', 'STORE_NBR'])['LYLTY_CARD_NBR'].nunique()\n",
    "    #print(Avg_Tcust)\n",
    "    \n",
    "   # Merge the metrics while considering the months\n",
    "    result1 = pd.merge(T_sales, T_Cust, how='outer', on=[ 'Month', 'STORE_NBR'])\n",
    "    #print(result1.columns)\n",
    "    result2 =  pd.merge(result1, Avg_Tcust, how='outer', on=['Month','STORE_NBR'])\n",
    "    #print(result2.columns)  # Check the actual number of columns\n",
    "\n",
    "   # Clarifying the name of the columns;\n",
    "    result2.columns = [ 'Month', 'STORE_NBR', 'M_SalesRevenue', 'M_NumberOfCustomers', 'M_AvgTranscPerCustomers']\n",
    "    \n",
    "    return result2\n",
    "\n",
    "Metrics = create_metrics(df)\n",
    "metrics = pd.DataFrame(Metrics)\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e9a245-dcc0-42f6-97d0-f2f86f6fbe12",
   "metadata": {},
   "source": [
    "# SELECT CONTROL STORES\n",
    "#### USING THE METRICS TO FIND THE CONTROL STORES FOR THE GIVEN TRIAL STORES\n",
    "\n",
    "Trial Stores: 77, 86 and 88\r\n",
    "* Write a function\r",
    "* Consider using Pearson correlatio\n",
    "*  Or metric such as a magnitude distance e.g Observed distance - minimum distance)/(Maximum distance - minimum distance) as a measre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06cd4ce-7a12-444e-a5e6-193ecfc5368d",
   "metadata": {},
   "source": [
    "My ideas:\n",
    "\n",
    "* Speicify the trial stores in the function.\n",
    "* Create another dataframe with just the trial stores and their respective metrics present\n",
    "* Create another dataframe that excludes the trial stores within the function.\n",
    "* Use Pearson correlation to measure the relationship between the trial stores metrics and the other stores metrics\n",
    "* * Aggregate metrics by Month i.e calculate the monthly average of your three metrics for both groups\n",
    "  * Merge the dataframes for comparison\n",
    "  * Compute Pearson correlation between the trial stores and other stores for each metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0f192775-6d0d-44cc-91d9-aadc510e6309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Final Selected Control Stores ###\n",
      "\n",
      "### Correlation for Trial Store 77 ###\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot join with no overlapping index names",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 67\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    # Merge trial and other stores' metrics on Month\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    merged_metrics = trial_metrics.merge(other_metrics, on=\"Month\", suffixes=(\"_trial\", \"_other\"))\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    #return correlations\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m### Final Selected Control Stores ###\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28mprint\u001b[39m(find_controlstores(metrics))\n",
      "Cell \u001b[1;32mIn[80], line 34\u001b[0m, in \u001b[0;36mfind_controlstores\u001b[1;34m(metrics, corr_min, corr_max)\u001b[0m\n\u001b[0;32m     31\u001b[0m trial_store_metrics \u001b[38;5;241m=\u001b[39m trial_pivot\u001b[38;5;241m.\u001b[39mxs(trial_store, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Compute correlation with all other stores\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m correlations \u001b[38;5;241m=\u001b[39m other_pivot\u001b[38;5;241m.\u001b[39mcorrwith(trial_store_metrics, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(correlations)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Convert to a dataframe for better readavitlity\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3-2024\\Lib\\site-packages\\pandas\\core\\frame.py:10954\u001b[0m, in \u001b[0;36mDataFrame.corrwith\u001b[1;34m(self, other, axis, drop, method, numeric_only)\u001b[0m\n\u001b[0;32m  10952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numeric_only:\n\u001b[0;32m  10953\u001b[0m     other \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39m_get_numeric_data()\n\u001b[1;32m> 10954\u001b[0m left, right \u001b[38;5;241m=\u001b[39m this\u001b[38;5;241m.\u001b[39malign(other, join\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m  10956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m  10957\u001b[0m     left \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32m~\\anaconda3-2024\\Lib\\site-packages\\pandas\\core\\generic.py:10090\u001b[0m, in \u001b[0;36mNDFrame.align\u001b[1;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[0;32m  10088\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m  10089\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, ABCDataFrame):\n\u001b[1;32m> 10090\u001b[0m     left, _right, join_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_frame(\n\u001b[0;32m  10091\u001b[0m         other,\n\u001b[0;32m  10092\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m  10093\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m  10094\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m  10095\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m  10096\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m  10097\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m  10098\u001b[0m         limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[0;32m  10099\u001b[0m         fill_axis\u001b[38;5;241m=\u001b[39mfill_axis,\n\u001b[0;32m  10100\u001b[0m     )\n\u001b[0;32m  10102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, ABCSeries):\n\u001b[0;32m  10103\u001b[0m     left, _right, join_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_series(\n\u001b[0;32m  10104\u001b[0m         other,\n\u001b[0;32m  10105\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10112\u001b[0m         fill_axis\u001b[38;5;241m=\u001b[39mfill_axis,\n\u001b[0;32m  10113\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3-2024\\Lib\\site-packages\\pandas\\core\\generic.py:10165\u001b[0m, in \u001b[0;36mNDFrame._align_frame\u001b[1;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis)\u001b[0m\n\u001b[0;32m  10156\u001b[0m     join_index, ilidx, iridx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m  10157\u001b[0m         other\u001b[38;5;241m.\u001b[39mindex, how\u001b[38;5;241m=\u001b[39mjoin, level\u001b[38;5;241m=\u001b[39mlevel, return_indexers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m  10158\u001b[0m     )\n\u001b[0;32m  10160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m  10161\u001b[0m     (axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m  10162\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_series\n\u001b[0;32m  10163\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mequals(other\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m  10164\u001b[0m ):\n\u001b[1;32m> 10165\u001b[0m     join_columns, clidx, cridx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m  10166\u001b[0m         other\u001b[38;5;241m.\u001b[39mcolumns, how\u001b[38;5;241m=\u001b[39mjoin, level\u001b[38;5;241m=\u001b[39mlevel, return_indexers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m  10167\u001b[0m     )\n\u001b[0;32m  10169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_series:\n\u001b[0;32m  10170\u001b[0m     reindexers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m: [join_index, ilidx]}\n",
      "File \u001b[1;32m~\\anaconda3-2024\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:267\u001b[0m, in \u001b[0;36m_maybe_return_indexers.<locals>.join\u001b[1;34m(self, other, how, level, return_indexers, sort)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(meth)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin\u001b[39m(\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m     sort: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    266\u001b[0m ):\n\u001b[1;32m--> 267\u001b[0m     join_index, lidx, ridx \u001b[38;5;241m=\u001b[39m meth(\u001b[38;5;28mself\u001b[39m, other, how\u001b[38;5;241m=\u001b[39mhow, level\u001b[38;5;241m=\u001b[39mlevel, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_indexers:\n\u001b[0;32m    269\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m join_index\n",
      "File \u001b[1;32m~\\anaconda3-2024\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4622\u001b[0m, in \u001b[0;36mIndex.join\u001b[1;34m(self, other, how, level, return_indexers, sort)\u001b[0m\n\u001b[0;32m   4620\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   4621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4622\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_join_multi(other, how\u001b[38;5;241m=\u001b[39mhow)\n\u001b[0;32m   4624\u001b[0m \u001b[38;5;66;03m# join on the level\u001b[39;00m\n\u001b[0;32m   4625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_multi \u001b[38;5;129;01mor\u001b[39;00m other\u001b[38;5;241m.\u001b[39m_is_multi):\n",
      "File \u001b[1;32m~\\anaconda3-2024\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4745\u001b[0m, in \u001b[0;36mIndex._join_multi\u001b[1;34m(self, other, how)\u001b[0m\n\u001b[0;32m   4743\u001b[0m \u001b[38;5;66;03m# need at least 1 in common\u001b[39;00m\n\u001b[0;32m   4744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overlap:\n\u001b[1;32m-> 4745\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join with no overlapping index names\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, MultiIndex) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, MultiIndex):\n\u001b[0;32m   4748\u001b[0m     \u001b[38;5;66;03m# Drop the non-matching levels from left and right respectively\u001b[39;00m\n\u001b[0;32m   4749\u001b[0m     ldrop_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(self_names \u001b[38;5;241m-\u001b[39m overlap, key\u001b[38;5;241m=\u001b[39mself_names_order)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot join with no overlapping index names"
     ]
    }
   ],
   "source": [
    "# Defining the trial stores\n",
    "\n",
    "\n",
    "def find_controlstores(metrics, corr_min= 0.85, corr_max=0.95):\n",
    "    \n",
    "    trial_stores = [77, 86, 88]   # Defined trial stores\n",
    "    control_stores = {} # Dictionary to store selected control stores\n",
    "    \n",
    "    # Creating separate dataframes\n",
    "    trial_df = metrics[metrics['STORE_NBR'].isin(trial_stores)]\n",
    "    \n",
    "    other_stores = metrics[~metrics['STORE_NBR'].isin(trial_stores)]\n",
    "    \n",
    "    \n",
    "    # Aggregate metrics by Month\n",
    "    trial_metrics = trial_df.groupby(['Month', 'STORE_NBR'])[['M_SalesRevenue', 'M_NumberOfCustomers', 'M_AvgTranscPerCustomers']].mean()\n",
    "    #print(trial_metrics)\n",
    "    \n",
    "    # Aggregate metrics for other stores\n",
    "    other_metrics = other_stores.groupby(['Month', 'STORE_NBR'])[['M_SalesRevenue', 'M_NumberOfCustomers', 'M_AvgTranscPerCustomers']].mean()\n",
    "    #print(other_metrics)\n",
    "\n",
    "    # Pivot the data to have stores as rows and metrics over time as columns\n",
    "    trial_pivot = trial_metrics.unstack(level=1)\n",
    "    other_pivot = other_metrics.unstack(level=1)\n",
    "\n",
    "    for trial_store in trial_stores:\n",
    "        print(f\"\\n### Correlation for Trial Store {trial_store} ###\")\n",
    "\n",
    "        # Extract data for the current trial store\n",
    "        trial_store_metrics = trial_pivot.xs(trial_store, axis=1, level=1)\n",
    "        \n",
    "        # Compute correlation with all other stores\n",
    "        correlations = other_pivot.corrwith(trial_store_metrics, axis=1)\n",
    "        \n",
    "        # Convert to a dataframe for better readavitlity\n",
    "        corr_df = correlations.reset_index()\n",
    "        corr_df.columns = ['STORE_NBR', 'Correlation']\n",
    "\n",
    "        # Filter stores within the giben correlation range\n",
    "        suitable_stores = corr_df[(corr_df['Correlation'] >= corr_min) & (corr_df['Correlation'] <= corr_max)]\n",
    "\n",
    "        # Store selected control stores for this trial store\n",
    "        control_stores[trial_store] = suitable_stores['STORE_NBR'].tolist()\n",
    "\n",
    "        # Display correlations\n",
    "        print(suitable_stores)\n",
    "\n",
    "    return control_stores  # Returns a dictionary of selected control stores\n",
    "                                   \n",
    "\n",
    "    '''\n",
    "    # Merge trial and other stores' metrics on Month\n",
    "    merged_metrics = trial_metrics.merge(other_metrics, on=\"Month\", suffixes=(\"_trial\", \"_other\"))\n",
    "\n",
    "    # Compute Pearson correlation for each metric\n",
    "    correlations = merged_metrics.corr(method='pearson')\n",
    "\n",
    "    # Display correlations between trial and other stores\n",
    "    print(correlations.loc[['M_SalesRevenue_trial', 'M_NumberOfCustomers_trial', 'M_AvgTranscPerCustomers_trial'],\n",
    "          ['M_SalesRevenue_other', 'M_NumberOfCustomers_other', 'M_AvgTranscPerCustomers_other']])\n",
    "\n",
    "    #return correlations\n",
    "    '''\n",
    "print('\\n### Final Selected Control Stores ###')\n",
    "print(find_controlstores(metrics))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85d185c-ee62-4561-9511-97606553a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot ( x = 'STORE_NBR', y = 'M_SalesRevenue', data = metrics)\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bf4c64-596c-473c-807f-3a8faae26481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
